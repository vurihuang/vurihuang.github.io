#+title: Vuri's blog
#+author: vuri

#+hugo_auto_set_lastmod: t
#+hugo_base_dir: .
#+hugo_section: .

#+options: toc:2

* Posts
:properties:
:export_hugo_section: posts
:end:

** DONE 使用 net/http 启动一个 web server                          :@golang:
:properties:
:export_file_name: golang-net-http-server
:export_date: 2020-08-29
:end:

*** 一个例子

#+begin_src go
package main

import (
	"fmt"
	"net/http"
)

func main() {
	http.HandleFunc("/hello", hello)

	if err := http.ListenAndServe(":8012", nil); err != nil {
		panic(err)
	}
}

func hello(w http.ResponseWriter, req *http.Request) {
	_, _ = fmt.Fprintf(w, "hello\n")
}
#+end_src

*** 内部实现

我们先来看下 ~http.ListenAndServe~ 函数：

#+begin_src go
func ListenAndServe(addr string, handler Handler) error {
    server := &Server{Addr: addr, Handler: handler}
    return server.ListenAndServe()
}
#+end_src

会进一步调用 ~Server~ 的 ~ListenAndServer~ 函数：

#+begin_src go
func (srv *Server) ListenAndServe() error {
    // ...

    addr := srv.Addr
    if addr == "" {
        addr = ":http"
    }
    ln, err := net.Listen("tcp", addr)
    if err != nil {
        return err
    }
    return srv.Serve(ln)
}
#+end_src

该函数用来监听指定的 TCP 地址， ~Listen~ 函数会返回一个 ~Listener~ 并调用 ~Serve~ 函数。

#+begin_src go
func (srv *Server) Serve(l net.Listener) error {
    // ...

    baseCtx := context.Background()

    // ...

    ctx := context.WithValue(baseCtx, ServerContextKey, srv)
    for {
        rw, err := l.Accept()
        
        // ...

        c := srv.newConn(rw)
        // ...
        go c.serve(connCtx)
    }
}
#+end_src

我们先忽略 ~Serve~ 函数具体实现的细节，先看下大致的函数处理流程。 ~Serve~ 函数接收并为每一个连接请求都创建一个 goroutine 进行处理， ~serve~ 函数会读取请求的 ~request~ 并调用 ~srv.Handler~ 来具体处理对应的请求。

在这里调用了 ~l.Accept()~ 函数返回一个 ~conn~ 连接，我们回过头来看下前面 ~ln, err := net.Listen("tcp", addr)~ 做了些什么事情， ~ln~ 是 ~Listener~ 接口的一个实现：

#+begin_src go
type Listener interface {
    // Accept 等待并返回请求的连接。
    Accept() (Conn, error)

    // Close 关闭该 listener。
    Close() error

    // Addr 返回该 listener 监听的地址。
    Addr() Addr
}
#+end_src

~Listen~ 函数这里是直接调用了 ~lc.Listen~ 函数：

#+begin_src go
func Listen(network, address string) (Listener, error) {
    var lc ListenConfig
    return lc.Listen(context.Background(), network, address)
})
#+end_src

#+begin_src go
// Listen 监听本地网络地址。
// network 的值必须是 "tcp", "tcp4", "tcp6", "unix" 或者 "unixpacket"。
// 如果 address 参数中的端口值为 "" 或者 "0"，例如 "127.0.0.1:" 或者 "[::1]:0"，
// 那么会随机选一个可使用的端口作为使用。
func (lc *ListenConfig) Listen(ctx context.Context, network, address string) (Listener, error) {
    addrs, err := DefaultResolver.resolveAddrList(ctx, "listen", network, address, nil)
    // ...

    var l Listener
    la := addrs.first(isIPv4)
    switch la := la.(type) {
        case *TCPAddr:
            l, err = sl.listenTCP(ctx, la)
        case *UnixAddr:
            l, err = sl.listenUnix(ctx, la)
        // ...
    }

    // ...
    return  l, nil
}
#+end_src

前面得到的 ~ln Listener~ 实例就是从这里得到，因为我们指定了 tcp 参数，这里调用的正是 ~sl.listenTCP~ 函数。

#+begin_src go
func (sl *sysListener) listenTCP(ctx context.Context, laddr *TCPAddr) (*TCPListener, error) {
    // 创建一个 socket，得到 file descriptor 文件描述符，
    fd, err := internetSocket(ctx, sl.network, laddr, nil, syscall.SOCK_STREAM, 0, "listen", sl.ListenConfig.Control)
    // ...
    return &TCPListener{fd: fd, lc: sl.ListenConfig}, nil
}
#+end_src

既然我们知道了上面的 ~Listener~ 指的就是 ~TCPListener~ ，那么上面 ~l.Accept()~ 函数得到的 ~rw~ 值又是什么东西呢，
这就还得看下 ~TCPListener.Accept~ 函数里头返回的具体是什么：

#+begin_src go
// Accept 被调用后返回一个连接.
func (l *TCPListener) Accept() (Conn, error) {
    // ...
    c, err := l.accept()
    // ...
    return c, nil
}

func (ln *TCPListener) accept() (*TCPConn, error) {
    fd, err := ln.fd.accept()
    // ...
    tc := newTCPConn(fd)
    // ...
    return tc, nil
}
#+end_src

~accept~ 函数这里返回的就是一个 TCP 连接对象，所以到目前为止的整体流程是：

1. 首先根据给定协议和地址（地址包含端口号），创建 socket，得到一个 Listener，用来监听特定网络地址的请求；
2. 在一个循环体里不停接收监听地址的请求，处理该 TCP 连接请求；
3. 最终每一个请求都会 ~go c.serve(connCtx)~ 发起一个 goroutine 来进行处理；

#+begin_src go
func (c *conn) serve(ctx context.Context) {
    // ...

    for {
        // 读取 HTTP 请求并解析，将一部分数据填充到 http.Request 对象中。
        w, err := c.readRequest(ctx)
        // ...
        // 进行路由匹配选择对应的 Handler 方法进行处理。
        serverHandler{c.server}.ServeHTTP(w, w.req)
        // ...
        // 收尾工作，write 我们的 response 数据，复用 bufio.Reader 来读取下一次的 request body。
        w.finishRequest()
        // ...
    }
}
#+end_src

#+begin_src go
func (sh sererHandler) ServeHTTP(rw ResponseWriter, req *Request) {
    handler := sh.srv.Handler
    if handler == nil {
        handler = DefaultServeMux
    }
    if req.RequestURI == "*" && req.Method == "OPTIONS" {
        handler = globalOptionsHandler{}
            }
    handler.ServeHTTP(rw, req)
}
#+end_src

还记得我们在一开始调用 ~http.HandleFunc()~ 函数吗，正是这里将我们自己编写的 handler 添加到 ~DefaultServeMux~ 中：

#+begin_src go
var DefaultServeMux = &defaultServeMux

var defaultServeMux = ServeMux
#+end_src

可以看到，在调用 ~ListenAndServe~ 函数 ~http.Handler~ 参数为 ~nil~ 的情况，使用的是 ~DefaultServeMux~ ，用的正是 ~ServeMux~ 对象：

#+begin_src go
type ServeMux struct {
	mu    sync.RWMutex
	m     map[string]muxEntry
	es    []muxEntry // 根据路由长度排序的数组，路由长度从最长到最短。
	hosts bool       // 是否存在路由包含主机名，有的话在匹配是必须 host+path 都满足 pattern 才行。
}

type muxEntry struct {
	h       Handler
	pattern string
}
#+end_src

我们来看下 handler 是如何添加到我们的 ~ServeMux~ 中的：

#+begin_src go
func (mux *ServeMux) Handle(pattern string, handler Handler) {
    mux.mu.Lock()
    defer mux.mu.Unlock()

    // ...
    if mux.m = nil {
        mux.m = make(map[string]muxEntry)
    }
    e := muxEntry{h: handler, pattern: pattern}
    mux.m[pattern] = e
    if pattern[len(pattern)-1] == '/' {
        mux.es = appendSorted(mux.es, e)
    }

    if pattern[0] != '/' {
        mux.hosts = true
    }
}

func appendSorted(es []muxEntry, e muxEntry) []muxEntry {
    n := len(es)
    // 得到满足条件的插入下标。
    i := sort.Search(n, func(i int) bool {A
        return len(es[i].pattern) < len(e.pattern)
    })
    if i == n {
        return append(es, e)
    }

    // 先对 slice 进行扩容，再将 pattern 更短的成员放到索引 i 的后面。
    es = append(es, muxEntry{})
    copy(es[i+1:], es[i:])
    es[i] = e
    return es
}
#+end_src

知道如何构造 ~ServeMux~ 后，剩下的就是在得到一个请求，如何根据请求的 path 得到 pattern 对应的 handler 的逻辑了：

#+begin_src go
func (mux *ServeMux) ServeHTTP(w ResponseWriter, r *Request) {
    // ...
    h, _ := mux.Handler(r)
    h.ServeHTTP(w, r)
}

func (mux *ServeMux) Handler(r *Request) (h Handler, pattern string) {
    // ...
    host := stripHostPort(r.Host)
    path := cleanPath(r.URL.Path)

    // 如果 path 是 /tree 并且 handler 没有注册该 pattern，
    // 则尝试重定向到 /tree。
    if u, ok := mux.redirectToPathSlash(host, path, r.URL); ok {
        return RedirectHandler(u.String(), StatusMovedPermanently), u.Path
    }

    if path != r.URL.Path {
        _, pattern = mux.handler(host, path)
        url := *r.URL
        url.Path = path
        return RedirectHandler(url.String(), StatusMovedPermanently), pattern
    }

    return mux.handler(host, r.URL.Path)
}

func (mux *ServeMux) handler(host, path string) (h Handler, pattern string) {
    // ...
    // 如果 pattern 不是 '/' 开头，该值为 true，需要匹配 host+path
    if mux.hosts {
        h, pattern = mux.match(host + path)
    }
    // fallback，再尝试一次
    if h == nil {
        h, pattern = mux.match(path)
    }
    if h == nil {
        h, pattern = NotFoundHandler(), ""
    }

    return
}

// 真正处理路由匹配的业务逻辑。
func (mux *ServeMux) match(path string) (h Handler, pattern string) {
    // 先进行全匹配。
    v, ok := mux.m[path]
    if ok {
        return v.h, v.pattern
    }

    // 根据最左最长优先匹配原则来匹配路由。
    // 如果我们定义的 pattern 为 /hello/，
    // 那么是可以匹配 /hello/, /hello/abc 路由的。
    for _, e := range mux.es {
        if strings.HasPrefix(path, e.pattern) {
            return e.h, e.pattern
        }
    }
    return nil, ""
}
#+end_src

** DONE Golang Context with value                                 :@golang:
:properties:
:export_file_name: golang-context-with-value
:export_date: 2020-08-20
:end:

今天遇到个很有意思的一段代码，这段程序会打印出什么结果：

#+begin_src go
  package main

  import (
    "context"
    "fmt"
  )

  func f(ctx context.Context) {
    context.WithValue(ctx, "foo", -6)
  }

  func main() {
    ctx := context.TODO()
    f(ctx)
    fmt.Println(ctx.Value("foo"))
    // -6
    // 0
    // <nil>
    // panic
  }
#+end_src

先让我们看看 ~context.TODO()~ 返回的结果是什么：

#+begin_src go
  var (
    background = new(emptyCtx)
    todo       = new(emptyCtx)
  )

  type emptyCtx int

  func TODO() Context {
    return todo
  }
#+end_src

~context.TODO()~ 返回的实例返回的正是一个 ~emptyCtx~ 对象，也就是 ~int~ ，它不能被 cancel，也不包含任何值，并且也没有 deadline。同时也不是一个空的结构体 ~struct{}~ ，因为它需要一个目标地址。

那么 ~context.WithValue~ 做了些什么事情呢：

#+begin_src go
type WithValue(parent Context, key, val interface{}) Context {
    if parent == nil {
        panic("cannot create context from nil parent")
    }
    if key == nil {
        panic("nil key")
    }
    if !reflectlite.TypeOf(key).Comparable() {
        panic("key is not comparable")
    }
    return &valueCtx{parent, key, val}
}

func valueCtx struct {
    Context,
    key, val interface{}
}
#+end_src

看到这里其实我们一开始的程序的结果已经很明显了，~WithValue~ 每次都会返回一个新的带有 key-value 值的上下文对象 ~valueCtx~ ，如果没有重新赋值，那么我们的 key-value 就会被丢失，并不会携带下去。

那么 ~context.Value~ 是怎么查找值的呢：

#+begin_src go
func (c *valueCtx) Value(key interface{}) interface{} {
	if c.key == key {
		return c.val
	}
	return c.Context.Value(key)
}
#+end_src

在查找指定 key 时，会先从当前的 context 对象中查看是否存在对应的 key，没有的话则回溯到 parent context 进行查找，那么什么时候是查找的尽头呢：

#+begin_src go
func (*emptyCtx) Value(key interface{}) interface{} {
	return nil
}
#+end_src

查找的尽头正是当 context 是一开始的 ~emptyCtx~ 空实现上下文对象时。

也正是因为 ~valueCtx~ 的实现如上面这样，是一种嵌套的结构，并且每次都是生成一个新的对象，官方的建议在使用时应该只传递必要的参数，来减少它的层级和数据的大小：

#+begin_src text
WithValue returns a copy of parent in which the value associated with key is val.
Use context Values only for request-scoped data that transits processes and APIs, not for passing optional parameters to functions.
#+end_src

** DONE Golang 实现一个协程池 -- rulego/fasthttp workerpool 源码介绍 :golang:
:properties:
:export_file_name: implements-a-goroutine-pool-in-go
:end:

*** 为什么要使用 goroutine 协程池

1. 在并发编程时，可以限制 goroutine 的数量，复用资源，提升性能;
2. 保持 CPU 缓存命中率，让 CPU 缓存处于活跃状态;

*** 如何实现一个简易 goroutine 协程池

1. 先对我们的目标进行抽象，池化的对象无非是启动、停止、提交任务:

  #+begin_src go
    type WorkerPool struct {
    }

    func (wp *WorkerPool) Start() {

    }

    func (wp *WorkerPool) Stop() {

    }

    func (wp *WorkerPool) Submit(fn func()) error {
      panic("implement me")
    }
  #+end_src

2. 生产端: 从 worker 池中获取一个 worker (=wp.getCh()=),并添加任务到任务队列中:

  #+begin_src go
    type workerChan struct {
      lastUseTime time.Time
      ch          chan func()
    }

    func (wp *WorkerPool) Submit(fn func()) error {
      ch := wp.getCh()
      if ch == nil {
        return errors.New("no idle workers")
      }
      ch.ch <- fn
      return nil
    }
  #+end_src

3. 消费端: 从任务队列中获取任务并执行:
   #+begin_src go
     func (wp *WorkerPool) workerFunc(ch *workerChan) {
       var fn func()
       for fn = range ch.ch {
         if fn == nil {
           break
         }
         fn()
         // Reset func
         fn = nil
       }
     }
   #+end_src
4. 有了生产和消费端,我们来看下如何真正创建 worker 以及 worker 的任务队列:

   #+begin_src go
     type WorkerPool struct {
       // MaxWorkersCount 最大 worker 上限
       MaxWorkersCount int
       // MaxIdleWorkerDuration worker 存活时间
       MaxIdleWorkerDuration time.Duration

       lock         sync.Mutex
       // workersCount 当前的 worker 数量
       workersCount int
       // ready 就绪的 worker 池
       ready          []*workerChan
       workerChanPool sync.Pool
     }

     func (wp *WorkerPool) getCh() *workerChan {
       var ch *workerChan
       createWorker := false

       // 这里操作的是数组,需要上锁保证并发安全
       wp.lock.Lock()
       ready := wp.ready
       n := len(ready) - 1
       if n < 0 { // 没有可运行的 worker 了
         if wp.workersCount < wp.MaxWorkersCount {
           createWorker = true
           wp.workersCount++
         }
       } else {
         // 采用 FILO(First In Last Out)先进后出的策略，最先结束的 worker 优先处理接下来的任务
         ch = ready[n]
         ready[n] = nil
         wp.ready = ready[:n]
       }

       wp.lock.Unlock()

       if ch == nil {
         if !createWorker {
           return nil
         }
         // 实例化一个 worker
         vch := wp.workerChanPool.Get()
         ch = vch.(*workerChan)

         go func() {
           wp.workerFunc(ch)
           wp.workerChanPool.Put(vch)
         }()
       }

       return ch
     }
   #+end_src

5. 接下来我们来看下如何对 worker 池进行初始化,也就是我们一开始的 =Start()= 方法:

   #+begin_src go
     func (wp *WorkerPool) Start() {
       if wp.stopCh != nil {
         return
       }

       wp.startOnce.Do(func() {
         wp.stopCh = make(chan struct{})
         stopCh := wp.stopCh
         wp.workerChanPool.New = func() any {
           return &workerChan{
             ch: make(chan func(), workerChanCap),
           }
         }

         // TODO: 异步清理 worker
       })
     }

     var workerChanCap = func() int {
       // 当 GOMAXPROCS=1 时,使用阻塞式 chan,
       // 将会立即处理提交的 fn,在 go1.5 以下的版本性能表现会更好.
       if runtime.GOMAXPROCS(0) == 1 {
         return 0
       }

       // 当 GOMAXPROCS>1 的话,使用非阻塞式 chan,
       // 如果 WorkerFunc 是 CPU 绑定(或者说是 CPU 具有亲和性),
       //  worker 任务刚好可以允许被延迟处理
       return 1
     }()
   #+end_src

   我们重点来看下 =workerChanCap= 方法, =runtime.GOMAXPROCS(0)= 什么意思呢,我们来看下注释:
   1. 当我们传入一个参数 =n= 时,会设置 =GOMAXPROCS= 为 =n=,并且返回之前的值;
   2. 而当 =n= <1时又什么都不做,不会修改当前设置值;

   所以其实是一个获取 =GOMAXPROCS= 的小技巧:

   #+begin_src go
     // GOMAXPROCS sets the maximum number of CPUs that can be executing
     // simultaneously and returns the previous setting. It defaults to
     // the value of runtime.NumCPU. If n < 1, it does not change the current setting.
     // This call will go away when the scheduler improves.
     func GOMAXPROCS(n int) int {
       if GOARCH == "wasm" && n > 1 {
         n = 1 // WebAssembly has no threads yet, so only one CPU is possible.
       }

       lock(&sched.lock)
       ret := int(gomaxprocs)
       unlock(&sched.lock)
       if n <= 0 || n == ret {
         return ret
       }

       stopTheWorldGC(stwGOMAXPROCS)

       // newprocs will be processed by startTheWorld
       newprocs = int32(n)

       startTheWorldGC()
       return ret
     }
   #+end_src

6. 有了启动的方法,也需要实现清理退出相关的方法,还记得我们在上面 =Start()= 函数预留了一个异步清理的逻辑,以及在退出时的 =Stop()= 逻辑:

   1. 在启动时,同时启动异步清理线程;
   2. 结束时通知并重置所有 worker 进程;
   3. 每个 worker 在运行时检查退出状态(mustStop)决定是否需要继续执行任务,或退出;

   #+begin_src go
     func (wp *WorkerPool) Start() {
       // ...

       wp.startOnce.Do(func() {
         // ...

         // 异步清理 worker
         go func() {
           var scratch []*workerChan
           for {
             wp.clean(&scratch)
             select {
             case <-stopCh:
               return
             default:
               time.Sleep(wp.getMaxIdleWorkerDuration())
             }
           }
         }()
       })
     }

     func (wp *WorkerPool) Stop() {
       if wp.stopCh == nil {
         return
       }
       close(wp.stopCh)
       wp.stopCh = nil

       // 停止所有等待处理任务的 worker
       // 不需要一直等待那些正在处理的 worker 处理完,根据 mustStop 的状态进行判断
       wp.lock.Lock()
       ready := wp.ready
       for i := range ready {
         ready[i].ch <- nil
         ready[i] = nil
       }
       wp.ready = ready[:0]
       wp.mustStop = true
       wp.lock.Lock()
     }

     func (wp *WorkerPool) workerFunc(ch *workerChan) {
       for fn = range ch.ch {
         // ...
         fn = nil

         // 如果进入 mustStop 状态,则直接退出
         if !wp.release(ch) {
           break
         }
       }

       wp.lock.Lock()
       wp.workersCount--
       wp.lock.Unlock()
     }

     func (wp *WorkerPool) release(ch *workerChan) bool {
       ch.lastUseTime = time.Now()
       wp.lock.Lock()
       if wp.mustStop {
         wp.lock.Unlock()
         return false
       }
       wp.ready = append(wp.ready, ch)
       wp.lock.Unlock()
       return true
     }
   #+end_src

   异步清理任务队列的 =clean()= 代码逻辑:
   
   #+begin_src go
     func (wp *WorkerPool) clean(scratch *[]*workerChan) {
       maxIdleWorkerDuration := wp.getMaxIdleWorkerDuration()
       // 如果 worker 最近的最大存活时间没有处理任务,则进行清理
       criticalTime := time.Now().Add(-maxIdleWorkerDuration)

       wp.lock.Lock()
       ready := wp.ready
       n := len(ready)

       // 通过二分查找出可以被清理的 worker 起始下标
       l, r, mid := 0, n-1, 0
       for l <= r {
         mid = (l + r) / 2
         if criticalTime.After(wp.ready[mid].lastUseTime) {
           l = mid + 1
         } else {
           r = mid - 1
         }
       }

       i := r
       if i == -1 {
         wp.lock.Lock()
         return
       }

       ,*scratch = append((*scratch)[:0], ready[:i+1]...)
       m := copy(ready, ready[i+1:])
       for i = m; i < n; i++ {
         ready[i] = nil
       }
       wp.ready = ready[:m]
       wp.lock.Unlock()

       // 通知 worker 停止退出.
       // 由于任务队列 ch.ch 可能会阻塞,同时也有可能面临 non-local CPUs(即跨核间的并发访问)带来的处理延迟,
       // 这段重置退出逻辑需要放到上锁之外来处理
       tmp := *scratch
       for i := range tmp {
         tmp[i].ch <- nil
         tmp[i] = nil
       }
     }
   #+end_src

把整个代码串起来,就是在 [[https://github.com/valyala/fasthttp/blob/master/workerpool.go][fasthttp]] 库中的 workerpool 协程池的逻辑,用来高效处理 http connection 连接;
在 [[https://github.com/rulego/rulego/blob/main/pool/workerpool.go][rolego]] 库中,它进行简单的调整以适配各种 =fn= 函数的任务处理.
   
-----
Refs:

- [[https://github.com/valyala/fasthttp/blob/master/workerpool.go][fasthttp workerpool]]
- [[https://github.com/rulego/rulego/blob/main/pool/workerpool.go][rulego workerpool]]
- [[https://github.com/panjf2000/ants][ants: a high-performance and low-cost goroutine pool]]
  
** Setup My Blog with Hugo and Org Mode                :@emacs:emacs:orgmode:
:properties:
:export_file_name: setup-my-blog-with-hugo-and-org-mode
:end:

*** 安装 Hugo

#+begin_src shell
  $ brew install hugo
#+end_src

*** 项目初始化

#+begin_src shell
  $ hugo new site blog
  $ cd blog; git init .
  # 安装主题
  $ git submodule add https://github.com/luizdepra/hugo-coder.git themes/hugo-coder
#+end_src

*** 修改配置文件 hugo.toml

#+begin_src toml
baseurl = "http://www.example.com"
title = "example"
theme = "hugo-coder"
languagecode = "en"
defaultcontentlanguage = "en"

paginate = 20

[markup.highlight]
style = "github-dark"

[params]
  author = "example"
  info = ""
  description = ""
  keywords = "blog,developer,personal"
  avatarurl = "images/avatar.jpg"
  #gravatar = "john.doe@example.com"

  faviconSVG = "/img/favicon.svg"
  favicon_32 = "/img/favicon-32x32.png"
  favicon_16 = "/img/favicon-16x16.png"

  since = 2020

  enableTwemoji = true

  colorScheme = "auto"
  hidecolorschemetoggle = false

  # customCSS = ["css/custom.css"]
  # customSCSS = ["scss/custom.scss"]
  # customJS = ["js/custom.js"]

[taxonomies]
  category = "categories"
  series = "series"
  tag = "tags"
  author = "authors"

# Social links
[[params.social]]
  name = "Github"
  icon = "fa fa-github fa-2x"
  weight = 1
  url = "https://github.com/example/"

# Menu links
[[menu.main]]
  name = "Blog"
  weight = 1
  url  = "posts/"
[[menu.main]]
  name = "About"
  weight = 2
  url = "about/"
#+end_src

*** 创建第一篇 Hello World 文章

#+begin_src shell
  $ hugo new content posts/hello-world.md
  $ cat content/posts/hello-world.md
#+end_src

显示如下内容：
#+begin_src markdown
  +++
  title = 'Hello World'
  date = 2023-10-14T01:31:21+08:00
  draft = true
  +++
#+end_src

在文本中追加内容 =hello world= ，启动 Hugo Server：

#+begin_src shell
  $ echo 'hello world' >> content/posts/hello-world.md
  # 同时构建草稿文章
  $ hugo server --buildDrafts
  # ...
  # Web Server is available at http://localhost:62743/ (bind address 127.0.0.1)
  # ...
#+end_src

打开浏览器，访问 =http://localhost:62743/= ：

file:static/images/hello-world.png

*** 使用 org-mode 来编辑博客

1. 使用 =ox-hugo= 插件来支持 org 文件生成 markdown 文件：
   spacemacs 已经集成 =ox-hugo= 插件，直接启用即可：

   #+begin_src emacs-lisp
     dotspacemacs-configuration-layers
     '(org :variables
           org-enable-hugo-support t)
     )
   #+end_src
   
2. 在博客根目录下创建 org 文件，例如： =index.org=

   #+begin_src org
     ,#+title: Example's blog
     ,#+author: nobody

     ,#+hugo_auto_set_lastmod: t
     ,#+hugo_base_dir: .
     ,#+hugo_section: .

     ,#+options: toc:2

     ,* Posts
     :properties:
     :export_hugo_section: posts
     :end:

     ,** Hello world!
     :properties:
     :export_file_name: hello-world
     :end:

     Hello, this is my first article.
   #+end_src

   执行 =, e e= 或 =SPC SPC org-export-dispatch RET= 会看到如下窗口，再执行 =H H= 导出为 markdown 文件，并保存到 =content/posts= 目录下：

   file:static/images/org-export-dispatch-window.png

3. 保存后自动导出生成 markdown 文件

   每次执行 =, e e H H= 生成操作还挺繁琐，如何进行配置每次一保存 org 文件自动生成导出呢？

   在博客根目录下创建 =.dir-locals.el= 文件：

   #+begin_src emacs-lisp
     ((org-mode . ((eval . (org-hugo-auto-export-mode)))))
   #+end_src

** Emacs 之路                                                  :@emacs:emacs:
:properties:
:export_file_name: the-way-to-emacs
:end:

*** Setup with spacemacs

#+begin_src shell
  # 下载 emacs
  $ brew install --cask emacs

  # 推荐这个分支的 emacs 发行版，提供更好的原生 GUI 支持，下载对应所需的 release 版本
  # 解决 GUI 下的闪屏问题，更加丝滑
  # https://github.com/railwaycat/homebrew-emacsmacport

  # 启用 spacemacs 作为 emacs 的加载入口
  $ git clone https://github.com/syl20bnr/spacemacs spacemacs.d
  $ ln -s ~/dotfiles/spacemacs.d ~/.emacs.d

  # 启动 emacs（GUI模式），下载依赖
  $ emacs
  # 终端模式下：
  # $ emacs --nw

  # 将 spacemacs 的启动配置存到到自定义的 dotfiles 下，方便统一管理
  $ mkdir -p ~/dotfiles/.emacs.d
  $ mv ~/.spacemacs* ~/dotfiles/.emacs.d
  $ ln -s ~/dotfiles/.emacs.d/.spacemacs ~/.spacemacs
  $ ln -s ~/dotfiles/.emacs.d/.spacemacs.env ~/.spacemacs.env
#+end_src

*** Org mode

**** 语法

-----
Refs:

- [[https://orgmode.org/worg/org-syntax.html][org-syntax]]
**** 如何创建代码段

执行 ~, i b~ 弹出菜单选择框，再按 s ~s[src]~

#+BEGIN_SRC org
  ,#+BEGIN_SRC org
  ,#+END_SRC
#+END_SRC

**** 如何编辑代码段

~C-c '~ 进入编辑代码段界面， ~, c~ 保存修改， ~, k~ 撤销修改。

-----
Refs:
- [[https://orgmode.org/manual/Structure-of-Code-Blocks.html][Structure of Code Blocks]]
- [[https://andreyor.st/posts/2022-10-16-my-blogging-setup-with-emacs-and-org-mode/][setup-with-emacs-and-org-mode]]

**** TOC(Table of Contents)

-----
Refs:

- [[https://orgmode.org/manual/Table-of-Contents.html][Table-of-Contents]]

*** Markdown

**** 生成 TOC

执行 ~SPC SPC markdown-toc-generate-toc RET~

**** 预览

1. 安装 ~vmd~
  #+begin_src shell
    npm install -g vmd
  #+end_src
2. 配置实时预览引擎
   #+begin_src emacs-lisp
     dotspacemacs-configuration-layers '(
       (markdown :variables markdown-live-preview-engine 'vmd))
   #+end_src


*** Plugins

**** Treemacs

Repo: [[https://github.com/Alexander-Miller/treemacs][Treemacs]]

#+begin_quote
a tree layout file explorer for Emacs
#+end_quote

***** 如何使用

spacemacs 已经包含 treemacs layer，可以直接使用：

#+begin_src emacs-lisp
  dotspacemacs-configuration-layers
  '(treemacs :variables
             treemacs-use-git-mode 'deferred)
#+end_src

- 添加工程（Project）到工作空间（Workspace）中

  光标焦点移动到 Treemacs 窗口中，执行 =C-c C-p a= 或者 =SPC SPC treemacs-add-project RET=
  选择指定目录到工程中。

- 对工作空间的工程进行排序

  执行 =C-c C-w e= 或者 =SPC SPC treemacs-edit-workspaces RET= ，会弹出窗口对文件进行编辑：

  #+begin_src org
    ,#+TITLE: Edit Treemacs Workspaces & Projects
    # Call ~treemacs-finish-edit~ or press ~C-c C-c~ when done.
    # [[https://github.com/Alexander-Miller/treemacs#conveniently-editing-your-projects-and-workspaces][Click here for detailed documentation.]]
    # To cancel you can simply kill this buffer.

    ,* Default
    ,** dotfiles
     - path :: ~/dotfiles
  #+end_src

  确认编辑修改后， =C-c C-c= 进行保存并退出。

** Kubectl 速查表                                                  :@kubernetes:cheatsheet:
:properties:
:export_file_name: kubectl-cheatsheet
:end:

*** Node
**** 查看 Node 资源使用情况

#+begin_src shell
  $ kubectl top node
  NAME                    CPU(cores)   CPU%        MEMORY(bytes)   MEMORY%
  172.16.192.36           1961m        12%         16885Mi         61%
  172.16.193.199          839m         5%          8046Mi          27%
  172.16.193.75           1915m        12%         10597Mi         38%
#+end_src

**** 获取指定Node上的pod列表

#+begin_src shell
  $ kubectl get po -A -o wide --field-selector spec.nodeName=172.16.192.36
  NAMESPACE     NAME                   READY    STATUS    RESTARTS   AGE     IP               NODE            NOMINATED NODE   READINESS GATES
  kube-system   kube-proxy-6gbzq       1/1      Running   0          13d     172.16.192.36    172.16.192.36   <none>           <none>
  kube-system   node-local-dns-tqpkz   1/1      Running   0          2d7h    172.16.192.36    172.16.192.36   <none>           <none>
  kube-system   kube-proxy-6gbzq       1/1      Running   0          13d     172.16.192.36    172.16.192.36   <none>           <none>
#+end_src

**** 获取节点总可用资源

#+begin_src shell
  $ kubectl get node -o=custom-columns="NODE:.metadata.name,ALLOCATABLE CPU:.status.allocatable.cpu,ALLOCATABLE MEMORY:.status.allocatable.memory"
  NODE                    ALLOCATABLE CPU   ALLOCATABLE MEMORY
  172.16.192.36           15600m            28262728Ki
  172.16.193.199          15890m            30121540Ki
  172.16.193.75           15600m            28262728Ki
#+end_src

**** 节点更新维护

#+begin_src shell
  # 1. 标记节点不可被调度
  $ kubectl cordon 172.16.192.36

  # 2.驱逐节点上的所有 pod（除daemonset），并删除临时盘
  $ kubectl drain 172.16.192.36 --ignore-daemonsets --delete-emptydir-data

  # 3. 重新标记节点为可调度
  $ kubectl uncordon 172.16.192.36
#+end_src

*** Pod

**** 设置Pod 调度策略

硬亲和（ ~requiredDuringSchedulingIngoredExecution~ ）：
#+begin_src yaml
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
            - key: foo
              operator: In
              values:
              - bar
#+end_src

软亲和（ ~preferredDuringSchedulingIgnoredExecution~ ）
#+begin_src yaml
  nodeAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
    - preference:
        matchExpressions:
        - key: foo
          operator: In
          values:
          - ""
      weight: 100
#+end_src

** Makefile 速查表                                                 :cheatsheet:
:properties:
:export_file_name: makefile-cheatsheet
:end:

*** Missing separator

~make~ 使用 ~tab~ 来进行缩进，用空格缩进则报错；如果是 ~tab~ ，会以 ~^I~ 符号呈现，可以通过以下方式进行检查：

#+begin_src shell
  $ cat Makefile
  .PHONY: print
  print:
  echo "test"
  echo "test"

  $ make print 
  Makefile:3: *** missing separator.  Stop.

  $ cat -e -t -v Makefile
  .PHONY: print$
  print:$
  echo "test"$
  ^Iecho "test"$
#+end_src

*** 在 Makefile 中使用 $ 符号

在 Makefile 中，需要区分 ~$~ 的使用，是为了引用变量例如 ~$variable~ ；还是需要使用 ~$~ 传递给 shell 命令；因此如果单纯想要使用 ~$~ ，就需要重复写两遍 ~$$~ 进行转义：

#+begin_src makefile
  # 无效用法：
  .PHONY: replace
    echo ' foo' | sed 's/foo$/bar/g'

  # 正确用法：
  .PHONY: replace
    echo ' foo' | sed 's/foo$$/bar/g'
#+end_src

-----
Refs:
- [[https://www.gnu.org/software/make/manual/make.html#Rule-Introduction][make规则介绍]]
- [[https://www.gnu.org/software/make/manual/make.html#Using-Variables][Using Variables]]
- [[https://pubs.opengroup.org/onlinepubs/9699919799/utilities/make.html][make macros]]

** 【译】Emacs 入门指南
:properties:
:export_file_name: beginners-guide-to-emacs
:end:

原文: [[https://www.masteringemacs.org/article/beginners-guide-to-emacs][An Emacs Tutorial: Beginner’s Guide to Emacs]]


** TODO 使用 GDB 调试 Go 代码
:properties:
:export_file_name: gdb-with-golang
:end:

** TODO The hardway to Rust
:properties:
:export_file_name: the-hardway-to-rust
:end:

*** 00-Setup
**** Install

=rustup= 是 Rust 的安装程序，通过下面这个方式进行安装:

#+begin_src shell
  $ curl --proto '=https' --tlsv1.2 https://sh.rustup.rs -sSf | sh

  $ rustup -V
  rustup 1.26.0 (5af9b9484 2023-04-05)
  info: This is the version for the rustup toolchain manager, not the rustc compiler.
  info: The currently active `rustc` version is `rustc 1.73.0 (cc66ad468 2023-10-03)`

  $ rustc -V
  rustc 1.73.0 (cc66ad468 2023-10-03)

  $ cargo -V
  cargo 1.73.0 (9c4383fb5 2023-08-26)
#+end_src

如何进行版本更新:

#+begin_src shell
  $ rustup update
#+end_src

执行 =rustup doc= 打开本地文档

**** Emacs/Spacemacs

在 Emacs/Spacemacs 上进行环境配置，启用 =Rust layer= ：

#+begin_src emacs-lisp
  (dotspacemacs-configuration-layers
   '(
     (rust :variables
           rustic-format-on-save t))
  )
#+end_src

**** 配置 rust-analyzer

=rust-analyzer= 是 =Rust= 的 =LSP(Language Server Protocol)= 的实现，提供自动补全、跳转等功能。

#+begin_src shell
  $ brew install rust-analyzer
#+end_src

*** 01-Hello world

创建工程目录 =l01-hello-world=

#+begin_src shell
  $ mkdir l01-hello-world && cd l01-hello-world && touch main.rs
#+end_src

添加 =main.rs= 文件并保存如下内容：

#+begin_src rust
  fn main() {
      println!("Hello world!");
  }
#+end_src

#+begin_src shell
  $ rustc main.rs
  $ ./main
  Hello world!
#+end_src

*** 02-Hello Cargo

#+begin_src shell
  # 创建工程
  $ cargo new l02-hello-cargo

  $ tree -L 2 l02-hello-cargo
  l02-hello-cargo
  ├── Cargo.lock
  ├── Cargo.toml
  ├── README.md
  ├── src
  │   └── main.rs
  └── target

  # 执行程序
  $ cd l02-hello-cargo
  $ cargo run
  Compiling l02-hello-cargo v0.1.0
  Finished dev [unoptimized + debuginfo] target(s) in 0.56s
  Running `target/debug/l02-hello-cargo`
  Hello, world!

  # 等价于
  $ cargo build
  $ ./target/debug/l02-hello-cargo
  Hello, world!

  # 在 release 模式下，采用编译优化
  $ cargo run --release
  $ cargo build --release
#+end_src
